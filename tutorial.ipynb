{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(lower=True, batch_first=False, fix_length=200)\n",
    "LABEL = torchtext.data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = torchtext.datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'text': <torchtext.data.field.Field object at 0x0000018D451A4348>, 'label': <torchtext.data.field.Field object at 0x0000018D451A4088>}\n",
      "{'text': ['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy.', 'it', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life,', 'such', 'as', '\"teachers\".', 'my', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'bromwell', \"high's\", 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '\"teachers\".', 'the', 'scramble', 'to', 'survive', 'financially,', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', \"teachers'\", 'pomp,', 'the', 'pettiness', 'of', 'the', 'whole', 'situation,', 'all', 'remind', 'me', 'of', 'the', 'schools', 'i', 'knew', 'and', 'their', 'students.', 'when', 'i', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school,', 'i', 'immediately', 'recalled', '.........', 'at', '..........', 'high.', 'a', 'classic', 'line:', 'inspector:', \"i'm\", 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers.', 'student:', 'welcome', 'to', 'bromwell', 'high.', 'i', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'bromwell', 'high', 'is', 'far', 'fetched.', 'what', 'a', 'pity', 'that', 'it', \"isn't!\"], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print('train.fields', train.fields)\n",
    "print(vars(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, vectors=torchtext.vocab.GloVe(name='6B', dim=300), max_size=10000, min_freq=10)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs)\n",
    "# print(TEXT.vocab.vectors)\n",
    "# print(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 32])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iter, test_iter = torchtext.data.BucketIterator.splits((test, train), batch_size=32, device=device, shuffle=True)\n",
    "\n",
    "train_iter.repeat = False\n",
    "test_iter.repeat = False\n",
    "\n",
    "batch = next(iter(train_iter))\n",
    "batch.text\n",
    "print(batch.text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBRnn(torch.nn.Module):\n",
    "    def __init__(self, n_vocab, hidden_size, n_cat, bs=1, nl=2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bs = bs\n",
    "        self.nl = nl\n",
    "        self.e = torch.nn.Embedding(n_vocab, hidden_size)\n",
    "        self.rnn = torch.nn.LSTM(hidden_size, hidden_size, nl)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, n_cat)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    \n",
    "    def forward(self, inp):\n",
    "        bs = inp.size()[1]\n",
    "        if bs != self.bs:\n",
    "            self.bs = bs\n",
    "        e_out = self.e(inp)\n",
    "        h0 = c0 = e_out.data.new(*(self.nl, self.bs, self.hidden_size)).zero_()\n",
    "        rnn_o, _ = self.rnn(e_out, (h0, c0))\n",
    "        rnn_o = rnn_o[-1]\n",
    "        fc = F.dropout(self.fc2(rnn_o), p=0.8)\n",
    "        return self.softmax(fc)\n",
    "    \n",
    "def fit(epoch, model, optimizer, data_loader, phase='training', volatile=False):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile = True\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        text, target = batch.text, batch.label\n",
    "        if torch.cuda.is_available():\n",
    "            text, target = text.cuda(), target.cuda()\n",
    "            \n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        output = model(text)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        running_loss += F.nll_loss(output, target, size_average=False).data.item()\n",
    "        preds = output.data.max(dim=1, keepdim=True)[1]\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        \n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    loss = running_loss/len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct / len(data_loader.dataset)\n",
    "    \n",
    "    print(f'{phase} loss is {loss:5.2f} and {phase} accuracy is {running_correct} / {len(data_loader.dataset)} {accuracy:10.4f}')\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is  0.74 and training accuracy is 13049 / 25000    52.1960\n",
      "validation loss is  0.70 and validation accuracy is 13780 / 25000    55.1200\n",
      "training loss is  0.69 and training accuracy is 14283 / 25000    57.1320\n",
      "validation loss is  0.68 and validation accuracy is 14558 / 25000    58.2320\n",
      "training loss is  0.67 and training accuracy is 15052 / 25000    60.2080\n",
      "validation loss is  0.67 and validation accuracy is 14990 / 25000    59.9600\n",
      "training loss is  0.66 and training accuracy is 15522 / 25000    62.0880\n",
      "validation loss is  0.67 and validation accuracy is 15204 / 25000    60.8160\n",
      "training loss is  0.65 and training accuracy is 15783 / 25000    63.1320\n",
      "validation loss is  0.66 and validation accuracy is 15469 / 25000    61.8760\n",
      "training loss is  0.65 and training accuracy is 16022 / 25000    64.0880\n",
      "validation loss is  0.66 and validation accuracy is 15606 / 25000    62.4240\n",
      "training loss is  0.64 and training accuracy is 16285 / 25000    65.1400\n",
      "validation loss is  0.65 and validation accuracy is 15740 / 25000    62.9600\n",
      "training loss is  0.64 and training accuracy is 16476 / 25000    65.9040\n",
      "validation loss is  0.65 and validation accuracy is 15874 / 25000    63.4960\n",
      "training loss is  0.63 and training accuracy is 16644 / 25000    66.5760\n",
      "validation loss is  0.64 and validation accuracy is 15995 / 25000    63.9800\n"
     ]
    }
   ],
   "source": [
    "model = EmbNet(len(TEXT.vocab.stoi), 300, 12000)\n",
    "\n",
    "model.embedding.weight.data = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.requires_grad = False\n",
    "optimizer = torch.optim.SGD([ param for param in model.parameters() if param.requires_grad == True ], lr=0.001)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "train_losses, train_accuracy = [], []\n",
    "val_losses, val_accuracy = [], []\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    epoch_loss, epoch_accuracy = fit(epoch, model, optimizer, train_iter, phase='training')\n",
    "    val_epoch_loss, val_epoch_accuracy = fit(epoch, model, optimizer, test_iter, phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.RNN(input_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
